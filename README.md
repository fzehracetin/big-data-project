# Map Reduce with Hadoop
This is a simple Big Data project that writes a dataset to HDFS and applies Hadoop MapReduce jobs on the dataset. MapReduce functions coded with Java. Web GUI developed with Python Flask. We worked with [Netflix Prize Dataset](https://www.kaggle.com/netflix-inc/netflix-prize-data) from Kaggle. We worked with Hadoop 3.2.1 and Java 8.

We coded 5 different descriptive statistical functions for map reduce jobs:
* [Aggeragate](https://github.com/fzehracetin/big-data-project/blob/main/javaProject/src/Sum.java)
* [Average](https://github.com/fzehracetin/big-data-project/blob/main/javaProject/src/Average.java)
* [Median](https://github.com/fzehracetin/big-data-project/blob/main/javaProject/src/Median.java)
* [Min-Max](https://github.com/fzehracetin/big-data-project/blob/main/javaProject/src/MinMax.java)
* [Standard Deviation](https://github.com/fzehracetin/big-data-project/blob/main/javaProject/src/StandardDeviation.java)

## Multi-node Hadoop Installation âš™

## Running Map Reduce Jobs ğŸƒğŸ»â€â™‚ï¸

## Web GUI ğŸ’»

